{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing packages\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "import string\n",
    "import nltk \n",
    "import matplotlib.pyplot as plt\n",
    "import textblob\n",
    "\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, classification_report, confusion_matrix, make_scorer, f1_score,accuracy_score, cohen_kappa_score, log_loss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Train and Test Datasets\n",
    "df_train = pd.read_csv(\"sentiment_train.csv\")\n",
    "df_test = pd.read_csv(\"sentiment_test.csv\")\n",
    "\n",
    "print(df_train.info())\n",
    "print(df_train.head())\n",
    "\n",
    "print(df_test.info())\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to count punctuation percentages\n",
    "def count_punct(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return round(count/(len(text) - text.count(\" \")), 3)*100\n",
    "\n",
    "#Calculate Sentence Length\n",
    "df_train['body_len'] = df_train['Sentence'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "#Calculate Punctuation Percentages\n",
    "df_train['punct%'] = df_train['Sentence'].apply(lambda x: count_punct(x))\n",
    "#Calculate Sentiment of Sentence\n",
    "df_train['sentiment'] = df_train['Sentence'].apply(lambda Text: TextBlob(Text).sentiment.polarity)\n",
    "#Replace numbers with space\n",
    "df_train['Sentence'] = df_train['Sentence'].str.replace('\\d+', ' ')\n",
    "#Replace any non characters and non spaces with a space\n",
    "df_train['Sentence'] = df_train['Sentence'].str.replace('[^\\w\\s]',' ')\n",
    "#Replace multiple spaces with a single space\n",
    "df_train['Sentence'] = df_train['Sentence'].str.replace('\\s+',' ',regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Sentence Length\n",
    "df_test['body_len'] = df_test['Sentence'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "#Calculate Punctuation Percentages\n",
    "df_test['punct%'] = df_test['Sentence'].apply(lambda x: count_punct(x))\n",
    "#Calculate Sentiment of Sentence\n",
    "df_test['sentiment'] = df_test['Sentence'].apply(lambda tweet: TextBlob(tweet).sentiment.polarity)\n",
    "#Replace numbers with space\n",
    "df_test['Sentence'] = df_test['Sentence'].str.replace('\\d+', ' ')\n",
    "#Replace any non characters and non spaces with a space\n",
    "df_test['Sentence'] = df_test['Sentence'].str.replace('[^\\w\\s]',' ')\n",
    "#Replace multiple spaces with a single space\n",
    "df_test['Sentence'] = df_test['Sentence'].str.replace('\\s+',' ',regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train)\n",
    "print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to convert text to lower and stem\n",
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[['Sentence','body_len','punct%','sentiment']]\n",
    "X_test = df_test[['Sentence','body_len','punct%','sentiment']]\n",
    "y_train = df_train['Polarity']\n",
    "y_test = df_test['Polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF Vectorizer\n",
    "tfidf_vect = TfidfVectorizer(max_features=500, min_df=6, max_df=0.8, analyzer=clean_text)\n",
    "tfidf_vect_fit = tfidf_vect.fit(X_train['Sentence'])\n",
    "\n",
    "tfidf_train = tfidf_vect_fit.transform(X_train['Sentence'])\n",
    "tfidf_test = tfidf_vect_fit.transform(X_test['Sentence'])\n",
    "\n",
    "feature_names = tfidf_vect.get_feature_names()\n",
    "\n",
    "#Concatenating TF-IDF features with other features\n",
    "X_train_vect = pd.concat([X_train[['body_len', 'punct%','sentiment']].reset_index(drop=True), \n",
    "           pd.DataFrame(tfidf_train.toarray(), columns=feature_names)], axis=1)\n",
    "X_test_vect = pd.concat([X_test[['body_len', 'punct%','sentiment']].reset_index(drop=True), \n",
    "           pd.DataFrame(tfidf_test.toarray(), columns=feature_names)], axis=1)\n",
    "\n",
    "print(X_train_vect.head())\n",
    "print(X_test_vect.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scoring function to optimize for F1 score\n",
    "scoring_function = make_scorer(f1_score, greater_is_better=True)\n",
    "\n",
    "#Parameter grid to test various hyper parameter values\n",
    "param_grid_rf = {\n",
    "    'max_depth': [80, 100, 110],\n",
    "    'max_features': [ 4, 5, 6],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 300, 500]\n",
    "}\n",
    "\n",
    "#Defining the Random Forest Classifier model\n",
    "classifier_RF = RandomForestClassifier(random_state=72042)\n",
    "\n",
    "#Hyper-parameter tuning using the function GridSearchCV for maximizing F1 score\n",
    "#5-fold cross-validation\n",
    "#Instantiate the grid search model\n",
    "grid_search_rf = GridSearchCV(estimator = classifier_RF, param_grid = param_grid_rf, \n",
    "                          cv = 5, scoring = scoring_function, n_jobs=-1,return_train_score = True, verbose = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Fitting the model on train dataset\n",
    "grid_search_RF = grid_search_rf.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting on Test dataset\n",
    "predictions = grid_search_RF.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Results on Test dataset\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(\"Accuracy = {:.2f}\".format(accuracy_score(y_test, predictions)))\n",
    "print(\"F1 Score = {:.2f}\".format(f1_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['body_len', 'punct%','sentiment'] + tfidf_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from treeinterpreter import treeinterpreter as ti\n",
    "\n",
    "prediction, bias, contributions = ti.predict(grid_search_RF.best_estimator_, X_test_vect)\n",
    "\n",
    "for i in range(len(X_test_vect)):\n",
    "    if y_test[i] == predictions[i]:\n",
    "        continue\n",
    "    print(\"Instance {}\".format(i))\n",
    "    df_test['Sentence'].iloc[i]\n",
    "    print(\"Bias (trainset mean) {}\".format(bias[i]))\n",
    "    print(\"Truth {}\".format(y_test[i]))\n",
    "    print(\"Prediction {}\".format(prediction[i, :]))\n",
    "    print(\"Feature contributions:\")\n",
    "    con = pd.DataFrame(data={print('feature': feature_names),\n",
    "                             print('value': X_test_vect.iloc[i]),\n",
    "                             print('negative contr': contributions[i][:, 0],\n",
    "                             print('positive contr': contributions[i][:, 1],\n",
    "                             print('abs contr': abs(contributions[i][:, 1]))})\n",
    "    con = con.sort_values(by=\"abs contr\", ascending=False)\n",
    "    con['polarity cumulative'] = con['negative contr'].cumsum() + bias[i][1]\n",
    "    con.head(10)\n",
    "    print(\"-\"*20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
